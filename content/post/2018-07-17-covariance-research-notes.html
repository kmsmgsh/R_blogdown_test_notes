---
title: Covariance research notes
author: Jiaming
date: '2018-07-17'
slug: covariance-research-notes
bibliography: Bibliography.bib
categories:
  - Statistics
tags:
  - matrix
  - Multivariable analysis
  - statistics, linear model, regression, covariance
  - covariance matrix
---



<p>This research has done by <span class="citation">Hastie (2017)</span> .
Actually not, this just a test about the citation in Rmarkdown.</p>
<p>Now let’s begin.</p>
<p>The origin of such research is by <span class="citation">Pourahmadi (1999)</span>. Such decomposition is very useful and full of statistical meaning of the result of reparameterization.</p>
<p>Other part of the research see the annual report. Here is about the related research maybe.</p>
<p>Google search key word is the paper that cited <span class="citation">Pourahmadi (1999)</span>. And select the recent research (maybe later than 2014?) with good journal.</p>
<p>This essay might be interesting <span class="citation">(Zwiernik, Uhler, and Richards 2017)</span>. From its title &quot; linear Gaussian covariance models&quot;, there is a thing should be mentioned.The first is what is the gaussian covariance model, what the link between this model with the T.W. Anderson’s linear modelling about the covariance models. The second thing is that it’s 2017 paper, so why it is so new.</p>
<p>Then let’s move to the abstract and introduction part.</p>
<p>Summary part: It seems like the model is not that simple. The MLE for this class of problem is a non-convex optimization problem? The work is based on some asymptotically distribution. Then this work prove under certain condition, this problem is asymptotically convex.
Not quite understand because I don’t understand what is such kind of model. Move to next part.</p>
<p>Pourhamadi 2011 is a review of covariance estimation problem.???
Need to check.</p>
<p>Okay find it <span class="citation">Pourahmadi (2011)</span>. Now it’s a break point for <span class="citation">Zwiernik, Uhler, and Richards (2017)</span>, let’s move to <span class="citation">Pourahmadi (2011)</span>.</p>
<p>From the abstract part, it said somethinga bout the high dimensional issue and GLM fitting issue, sparse estimation and graphic model issues, not quite understand. But after that, it comes to mention the Cholesky Decomposition, Spectral Decomposition and the Variance-Covariance Decomposition, which is three parameterisation method in previous research.</p>
<p>It’s a big introduction part with good literature review I think? should mark and read sometimes later. This is section1 and 2 for the previous methods. The next part is the regularization method, not quite understand, mark here.
Section 4 is an isolated Bayesian part, about the prior and other issues. The 4.4 is about autocorrelation model should be noted.</p>
<p>Break point back.</p>
<div id="refs" class="references">
<div id="ref-hastie2017generalized">
<p>Hastie, Trevor J. 2017. “Generalized Additive Models.” In <em>Statistical Models in S</em>, 249–307. Routledge.</p>
</div>
<div id="ref-pourahmadi1999joint">
<p>Pourahmadi, Mohsen. 1999. “Joint Mean-Covariance Models with Applications to Longitudinal Data: Unconstrained Parameterisation.” <em>Biometrika</em> 86 (3). Oxford University Press: 677–90.</p>
</div>
<div id="ref-pourahmadi2011covariance">
<p>———. 2011. “Covariance Estimation: The Glm and Regularization Perspectives.” <em>Statistical Science</em>. JSTOR, 369–87.</p>
</div>
<div id="ref-zwiernik2017maximum">
<p>Zwiernik, Piotr, Caroline Uhler, and Donald Richards. 2017. “Maximum Likelihood Estimation for Linear Gaussian Covariance Models.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 79 (4). Wiley Online Library: 1269–92.</p>
</div>
</div>
